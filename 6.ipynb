{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic setups \n",
    "import numpy as np\n",
    "from skimage import io\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_data\n",
    "from PCA import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import math\n",
    "def dataSplit(K,data):\n",
    "    \"\"\"This function is used to implement k-fold cross-validation\"\"\"\n",
    "    #Shuffle the dataset to get more accurate performance\n",
    "    \n",
    "    #print(\"original shape:\",data.shape)\n",
    "    \n",
    "    index = np.arange(0,len(data))\n",
    "    shuffle(index)\n",
    "    shuffled_data= data[index]\n",
    "    \n",
    "    \n",
    "    #print(\"shuffled shape:\",shuffled_data.shape)\n",
    "    \n",
    "    #Initialize list for train,test and val \n",
    "    train = []\n",
    "    val = []\n",
    "    test = []\n",
    "    \n",
    "    #Split the data into training, testing and handout set\n",
    "    size = len(data)\n",
    "    set_size = math.floor(size/K)\n",
    "\n",
    "    for i in range(K):\n",
    "        # select subsets of data\n",
    "        test_i = shuffled_data[i*set_size:(i+1)*set_size] #ith cut as training set for ith fold\n",
    "        \n",
    "        #print(\"shape of test_i\",test_i.shape)\n",
    "        \n",
    "        temp = (i+1)%K\n",
    "        val_i = shuffled_data[temp*set_size:(temp+1)*set_size] # (i+1)%kth cut as val set for ith fold\n",
    "        \n",
    "        #print(\"shape of val_i\",val_i.shape)\n",
    "        \n",
    "        if i < temp:\n",
    "            temp1 = shuffled_data[:i*set_size]\n",
    "            temp2 = shuffled_data[(temp+1)*set_size:]\n",
    "            train_i = np.concatenate((temp1, temp2),axis=0)\n",
    "            \n",
    "        if i > temp:\n",
    "            temp1 = shuffled_data[0:temp*set_size]\n",
    "            temp2 = shuffled_data[(temp+1)*set_size:i*set_size]\n",
    "            temp3 = shuffled_data[(i+1)*set_size:]\n",
    "            train_i_temp = np.concatenate((temp1, temp2),axis=0)\n",
    "            train_i = np.concatenate((train_i_temp, temp3),axis=0)\n",
    "            \n",
    "        #print(\"shape of train_i\",train_i.shape)\n",
    "        \n",
    "        train.append(train_i)\n",
    "        val.append(val_i)\n",
    "        test.append(test_i)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_flatten(img):\n",
    "    \"\"\"This function is used to convert 2-D images to 1-D vectors\"\"\"\n",
    "    flatten_img = []\n",
    "    for i in range(len(img)):\n",
    "        flatten_img.append(img[i].flatten())\n",
    "    return np.array(flatten_img)\n",
    "\n",
    "def projectPC(x,mean_image, eigen_values, eigen_vectors):\n",
    "    \"\"\"This function is used to project the data x on the given training set x_train\"\"\"\n",
    "    msd = x - mean_image\n",
    "    projected_image = np.matmul(msd,eigen_vectors)/eigen_values\n",
    "    projected = np.insert(projected_image,0,1,axis=1)\n",
    "    return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x.T) / np.sum(np.exp(x), axis=1)).T\n",
    "\n",
    "def to_class(x):\n",
    "    return x.argmax(axis=1)\n",
    "\n",
    "def accuracy(x,y,weight):\n",
    "    x = np.asmatrix(x)\n",
    "    y = np.asmatrix(y)\n",
    "    weight = np.asmatrix(weight)\n",
    "    \n",
    "    y_hat = softmax(x * weight.T)\n",
    "    print(\"shape of y_hat\",y_hat.shape)\n",
    "    \n",
    "    prediction =  to_class(y_hat)\n",
    "    \n",
    "    correct = np.zeros(y.shape[0])\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == prediction[i]:\n",
    "            correct[i]=1\n",
    "    accuracy = sum(correct)/len(correct) \n",
    "    return accuracy\n",
    "    \n",
    "def cross_entropy(x,y,weight):\n",
    "    x = np.asmatrix(x)\n",
    "    y = np.asmatrix(y)\n",
    "    weight = np.asmatrix(weight)\n",
    "    \n",
    "    #print(weight.shape)\n",
    "    \n",
    "    y_hat = softmax(x * weight.T)\n",
    "    \n",
    "    #print(\"shape of y,y_hat\",y.shape,y_hat.shape)\n",
    "    \n",
    "    cost = np.multiply(-y,np.log(y_hat))\n",
    "    \n",
    "    error = np.sum(cost)/len(x)\n",
    "    return error\n",
    "\n",
    "def gradientDescent(x,y,weight,learning_rate):\n",
    "    x = np.asmatrix(x)\n",
    "    y = np.asmatrix(y)\n",
    "    weight = np.asmatrix(weight)\n",
    "    \n",
    "    #print(\"checkgradD,weightshape:\",weight.shape)\n",
    "    print((x * weight).shape)\n",
    "    y_hat = softmax(x * weight.T)\n",
    "    error = y_hat-y\n",
    "    \n",
    "    #print(error.shape)\n",
    "    \n",
    "    gradient = x.T * error / len(x)\n",
    "    gradient= np.squeeze(np.asarray(gradient))\n",
    "    \n",
    "    print(\"checkgradD,gradientshape:\",gradient.shape)\n",
    "    \n",
    "    weight_updated = weight.T - learning_rate*gradient\n",
    "    weight_updated = np.asarray(weight_updated)\n",
    "    \n",
    "    print(\"checkgradD,weightshapeupdate:\",weight_updated.shape)\n",
    "    \n",
    "    return gradient,weight_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(481, 16)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car types: ['Convertible', 'Minivan', 'Pickup', 'Sedan'] \n",
      "\n",
      "Convertible: 149 # of images\n",
      "Minivan: 148 # of images\n",
      "Pickup: 150 # of images\n",
      "Sedan: 150 # of images\n"
     ]
    }
   ],
   "source": [
    "#Load data \n",
    "data,cnt = load_data(\"./aligned/\")\n",
    "\n",
    "\n",
    "minivan= data.get('Minivan')\n",
    "convertible = data.get('Convertible')\n",
    "pickup= data.get('Pickup')\n",
    "sedan = data.get('Sedan')\n",
    "\n",
    "\n",
    "minivan_flatten = img_flatten(minivan)\n",
    "convertible_flatten = img_flatten(convertible)\n",
    "pickup_flatten = img_flatten(pickup)\n",
    "sedan_flatten = img_flatten(sedan)\n",
    "\n",
    "#print(\"shape of minivan:\",minivan_flatten.shape)\n",
    "#print(\"shape of convertible:\",convertible_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fold = 10\n",
    "max_iter = 800\n",
    "learning_rate = 7\n",
    "num_PC = 15\n",
    "\n",
    "trainM, valM, testM = dataSplit(num_fold,minivan_flatten)\n",
    "trainC, valC, testC = dataSplit(num_fold,convertible_flatten)\n",
    "trainP, valP, testP = dataSplit(num_fold,pickup_flatten)\n",
    "trainS, valS, testS = dataSplit(num_fold,sedan_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of matrix: (800, 10)\n"
     ]
    }
   ],
   "source": [
    "#Initialize accuracy and error matrix\n",
    "train_error = np.zeros((max_iter,num_fold))\n",
    "val_error = np.zeros((max_iter,num_fold))\n",
    "test_error = np.zeros((max_iter,num_fold))\n",
    "            \n",
    "train_acc = np.zeros((max_iter,num_fold))\n",
    "val_acc = np.zeros((max_iter,num_fold))\n",
    "test_acc = np.zeros((max_iter,num_fold))\n",
    "\n",
    "average_train = np.zeros((1,max_iter))\n",
    "average_val = np.zeros((1,max_iter))\n",
    "\n",
    "test_accuracy = np.zeros((1,num_fold))\n",
    "\n",
    "print(\"shape of matrix:\",train_acc.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_PCs(eigenvectors,n):\n",
    "    \"\"\"This function is used plot top PCs\"\"\"\n",
    "    imgs = []\n",
    "    plt.figure()\n",
    "    for i in range(n):\n",
    "        eigen = eigenvectors[:,i]\n",
    "        image = np.reshape(eigen,(200,300))\n",
    "        imgs.append(image)\n",
    "        plt.subplot(2,n/2,i+1)\n",
    "        plt.imshow(imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th iteration :\n",
      "(481, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (481,16) and (4,16) not aligned: 16 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-e00e9ae8985e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradientDescent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m#print(\"shape of weight\",weight.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-af13acc40b46>\u001b[0m in \u001b[0;36mgradientDescent\u001b[1;34m(x, y, weight, learning_rate)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#print(\"checkgradD,weightshape:\",weight.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__rmul__'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (481,16) and (4,16) not aligned: 16 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "def one_hot(x):\n",
    "    onehot = np.zeros((x.size, 4))\n",
    "    onehot[np.arange(x.size),x.astype(int)[:,0]] = 1\n",
    "    return onehot\n",
    "\n",
    "for fold in range(num_fold):\n",
    "    print(\"%dth iteration :\" %(fold))\n",
    "    \n",
    "    #generate train,test and val set\n",
    "    train = np.concatenate((trainM[fold], trainC[fold], trainP[fold], trainS[fold]),axis=0)\n",
    "    test = np.concatenate((testM[fold], testC[fold], testP[fold], testS[fold]),axis=0)\n",
    "    val = np.concatenate((valM[fold], valC[fold], valP[fold], valS[fold]),axis=0)\n",
    "\n",
    "    #print(\"shape of train set:\",train.shape)\n",
    "    #print(\"shape of test set:\",test.shape)\n",
    "    #print(\"shape of val set:\",val.shape)\n",
    "    \n",
    "    y_train = np.concatenate((np.zeros(len(trainM[fold])), np.ones(len(trainC[fold])), 2*np.ones(len(trainP[fold])), 3*np.ones(len(trainS[fold]))), axis=0)\n",
    "    y_train= np.array([[i] for i in y_train])\n",
    "    y_train = one_hot(y_train)\n",
    "    #print(y_train)\n",
    "\n",
    "    y_test = np.concatenate((np.zeros(len(testM[fold])), np.ones(len(testC[fold])), 2*np.ones(len(testP[fold])), 3*np.ones(len(testS[fold]))), axis=0)\n",
    "    y_test = np.array([[i] for i in y_test])\n",
    "    y_test = one_hot(y_test)\n",
    "\n",
    "    y_val = np.concatenate((np.zeros(len(valM[fold])), np.ones(len(valC[fold])), 2*np.ones(len(valP[fold])), 3*np.ones(len(valS[fold]))), axis=0)\n",
    "    y_val = np.array([[i] for i in y_val])\n",
    "    y_val = one_hot(y_val)\n",
    "    \n",
    "    #Perform PCA to find top PCs on training set\n",
    "    projected, mean_image, top_sqrt_eigen_values, top_eigen_vectors = PCA(train, num_PC)\n",
    "    x_train = np.insert(projected, 0, 1, axis=1)\n",
    "\n",
    "    #Project test and val set on top PCs\n",
    "    x_test = projectPC(test,mean_image, top_sqrt_eigen_values, top_eigen_vectors)\n",
    "    x_val = projectPC(val,mean_image, top_sqrt_eigen_values, top_eigen_vectors)\n",
    "    \n",
    "    weight = np.zeros((len(x_train[0]),4))\n",
    "    #print(weight[:,0].shape)\n",
    "                      \n",
    "    for j in range(max_iter):\n",
    "        grad,weight = gradientDescent(x_train,y_train,weight,learning_rate)\n",
    "\n",
    "        #print(\"shape of weight\",weight.shape)\n",
    "    \n",
    "        train_error[j][fold] = cross_entropy(x_train,y_train,weight)\n",
    "        train_acc[j][fold] = accuracy(x_train,y_train,weight)\n",
    "                                                 \n",
    "        #Calculate the error for hold out set using updated weight\n",
    "        val_error[j][fold] = cross_entropy(x_val,y_val,weight)\n",
    "        val_acc[j][fold] = accuracy(x_val,y_val,weight)\n",
    "                                                 \n",
    "        #Calculate the error for test set using updated weight\n",
    "        test_error[j][fold] = cross_entropy(x_test,y_test,weight)\n",
    "        test_acc[j][fold] = accuracy(x_test,y_test,weight)\n",
    "        \n",
    "    val_temp = val_error[:,fold]\n",
    "    \n",
    "    #print(\"shape of val_temp:\",val_temp.shape)\n",
    "    \n",
    "    index_min = np.argmin(val_temp)\n",
    "    test_accuracy[0][fold] = test_acc[index_min][fold]\n",
    "    \n",
    "\n",
    "    plot_top_PCs(top_eigen_vectors,4)\n",
    "    #plt.savefig('./plots/5c_top4eign'+str(fold)+'th.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot average loss curves for training and val sets\n",
    "std_train = np.zeros((1,max_iter))\n",
    "std_val = np.zeros((1,max_iter))\n",
    "\n",
    "for q in range(max_iter):\n",
    "    average_train[0][q] = np.mean(train_error[q][:])\n",
    "    average_val[0][q] = np.mean(val_error[q][:])\n",
    "    std_train[0][q] = np.std(train_error[q][:])\n",
    "    std_val[0][q] = np.std(val_error[q][:])\n",
    "    \n",
    "plt.plot(average_train[0,:],color = 'red',label = 'Training loss')\n",
    "\n",
    "\n",
    "plt.title(\"Loss for training set with Learning rate =\"+str(learning_rate)+\", Number of PCs = \"+str(num_PC))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.legend()\n",
    "\n",
    "errorbar_x = np.zeros((1,int(max_iter/50) ))\n",
    "errorbar_train = np.zeros((1,int(max_iter/50)))\n",
    "errorbar_val = np.zeros((1,int(max_iter/50) ))\n",
    "errorbar_y_train = np.zeros((1,int(max_iter/50)))\n",
    "errorbar_y_val = np.zeros((1,int(max_iter/50)))\n",
    "\n",
    "for p in range(int(max_iter/50)):\n",
    "    \n",
    "    errorbar_x[0][p] = 50*(p+1)\n",
    "    errorbar_train[0][p] = std_train[0][50*(p+1)-1]\n",
    "    errorbar_val[0][p] = std_val[0][50*(p+1)-1]\n",
    "    errorbar_y_train[0][p] = average_train[0][50*(p+1)-1]\n",
    "    errorbar_y_val[0][p] = average_val[0][50*(p+1)-1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "plt.errorbar(errorbar_x[0,:], errorbar_y_train[0,:], errorbar_train[0,:],fmt = '.r', capsize=5)\n",
    "\n",
    "\n",
    "#plt.savefig('./plots/5c_loss_train_lr_'+str(learning_rate)+'_pc_'+str(num_PC)+'.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_val[0,:],color = 'blue',label = 'Val loss')\n",
    "plt.title(\"Loss for val set with Learning rate =\"+str(learning_rate)+\", Number of PCs = \"+str(num_PC))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.errorbar(errorbar_x[0,:], errorbar_y_val[0,:], errorbar_val[0,:],fmt = '.b', capsize=5)\n",
    "\n",
    "plt.legend()\n",
    "#plt.savefig('./plots/5c_loss_val_lr_'+str(learning_rate)+'_pc_'+str(num_PC)+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print testing accuracy\n",
    "test_acc_final = np.mean(test_accuracy)\n",
    "print(\"The final accuracy is :\",test_acc_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
